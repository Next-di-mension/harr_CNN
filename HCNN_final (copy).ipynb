{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchquantum as tq\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "from skimage import io\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define controlled hadamard gate\n",
    "sq2 = 1/np.sqrt(2)\n",
    "def controlled_H(qdev, target,control):\n",
    "      qdev.apply(tq.QubitUnitary(\n",
    "      has_params=True,init_params=([[1,0,0,0],[0,sq2,0,sq2],[0,0,1,0],[0,sq2,0,-sq2]]),wires=[target,control]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuanvolutionFilter(tq.QuantumModule):\n",
    "  # the __init__ method initializes the quantum device, the general encoder,\n",
    "  # a random quantum layer, and a measurement operator.\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n_wires = 4  # two ancillas\n",
    "        self.q_device = tq.QuantumDevice(n_wires=self.n_wires)\n",
    "        # encoding the input data\n",
    "        self.encoder = tq.GeneralEncoder(\n",
    "        [   {'input_idx': [0], 'func': 'ry', 'wires': [0]},\n",
    "            {'input_idx': [1], 'func': 'ry', 'wires': [1]},\n",
    "            {'input_idx': [2], 'func': 'ry', 'wires': [2]},\n",
    "            {'input_idx': [3], 'func': 'ry', 'wires': [3]},])\n",
    "        \n",
    "\n",
    "\n",
    "        # random circuit layer \n",
    "        self.q_layer = tq.RandomLayer(n_ops=8, wires=list(range(self.n_wires)))\n",
    "        self.measure = tq.MeasureAll(tq.PauliZ)\n",
    "        #self.expval = tq.expval()\n",
    "    \n",
    "# x has the dimension of (batch_size, 28, 28) representing a batch of greyscale images\n",
    "#The method first reshapes the input data into a 2D array of shape \n",
    "#(batch_size, 784) by concatenating adjacent 2x2 blocks of pixels.\n",
    "# data is the new reshaped tensor \n",
    "    def forward(self, x, use_qiskit=False):\n",
    "        bsz = x.shape[0] # batch size\n",
    "        size = 256 # height and width of an image\n",
    "        x = x.view(bsz, size, size) # view all data \n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        for c in range(0, size, 2):\n",
    "            for r in range(0, size, 2):\n",
    "                data = torch.transpose(torch.cat((x[:, c, r], x[:, c, r+1], x[:, c+1, r], x[:, c+1, r+1])).view(4, bsz), 0, 1)\n",
    "                if use_qiskit:\n",
    "                    data = self.qiskit_processor.process_parameterized(\n",
    "                        self.q_device, self.encoder, self.q_layer, self.measure, data)\n",
    "                else:\n",
    "                    self.encoder(self.q_device, data)\n",
    "                    \n",
    "                    #haar wavelet\n",
    "                    # level 1 \n",
    "                    self.q_device.h(wires = 3) \n",
    "                    self.q_device.swap([3,2])\n",
    "                    self.q_device.swap([2,1])\n",
    "                    self.q_device.swap([1,0])\n",
    "\n",
    "                    # level 2 \n",
    "                    controlled_H(self.q_device, target=2, control= 3)\n",
    "                    self.q_device.cswap([3,2,1])\n",
    "                    self.q_device.cswap([3,1,0])\n",
    "\n",
    "                    # level 3\n",
    "                    \n",
    "                    #self.q_device.ccx([2,3,4])\n",
    "                    #controlled_H(self.q_device, target=1, control= 4)\n",
    "                    #self.q_device.ccx([2,3,4])\n",
    "                    #perm\n",
    "                    #self.q_device.ccx([2,3,4])\n",
    "                    #self.q_device.cswap([4,1,0])\n",
    "                    #self.q_device.ccx([2,3,4])\n",
    "\n",
    "                    #level 4\n",
    "                    #self.q_device.ccx([2,3,4])\n",
    "                    #self.q_device.ccx([1,4,5])\n",
    "                    #controlled_H(self.q_device, target=0, control= 5)\n",
    "                    #self.q_device.ccx([1,4,5])\n",
    "                    #self.q_device.ccx([2,3,4])\n",
    "\n",
    "\n",
    "\n",
    "                    self.q_layer(self.q_device)\n",
    "                    data = self.measure(self.q_device)\n",
    "                    \n",
    "                    #for i in range(4):\n",
    "                    #    measure_result = []\n",
    "                    #    measure_result.append(tq.expval(self.q_device,wires=i, observables= tq.PauliZ(wires=i)))\n",
    "\n",
    "                    #    data = torch.tensor([measure_result])\n",
    "\n",
    "                    \n",
    "                data_list.append(data.view(bsz, 4)) # only keep the first 4 qubits\n",
    "        \n",
    "        result = torch.cat(data_list, dim=1).float()\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HybridModel(torch.nn.Module): \n",
    "    def __init__(self): \n",
    "        super().__init__() \n",
    "        self.qf = QuanvolutionFilter()\n",
    "        self.linear = torch.nn.Linear(4*128*128, 2) \n",
    "    def forward(self, x, use_qiskit=False):\n",
    "        with torch.no_grad():\n",
    "          x = self.qf(x, use_qiskit)\n",
    "        x = self.linear(x)\n",
    "        return F.softmax(x, -1) \n",
    "    # F.log_softmax is the log of the softmax function, which is a common choice for the output of a classification model.\n",
    "    \n",
    "class HybridModel_without_qf(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(256*256, 2)\n",
    "    \n",
    "    def forward(self, x, use_qiskit=False):\n",
    "        x = x.view(-1, 256*256)\n",
    "        x = self.linear(x)\n",
    "        return F.log_softmax(x, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset \n",
    "class Oral_Can_Data(Dataset):\n",
    "    '''Oral cancer dataset'''\n",
    "    def __init__(self, csv_file, root_dir,transform = None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations) # returns the number of samples in the dataset\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        image = np.array([image])\n",
    "        image = torch.tensor(image)\n",
    "        can_type = self.annotations.iloc[index, 1] # labels:  1 for non-cancerous, 2 for cancerous\n",
    "        can_type = torch.tensor([can_type])\n",
    "        can_type = can_type\n",
    "\n",
    "    \n",
    "        sample = {'image': image, 'can_type': can_type}\n",
    "        \n",
    "        for index in range(len(self.annotations)):\n",
    "            sample\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return (sample) # returns the image and the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "dataset = Oral_Can_Data(csv_file= '/home/iisers/Documents/oral_cancer_project/labels .csv',root_dir='/home/iisers/Documents/oral_cancer_project/Combined_data_resized')\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_set, val_set,  test_set = torch.utils.data.random_split(dataset, [train_size,val_size,test_size])\n",
    "\n",
    "dataflow = dict({'train' : train_set, 'valid': val_set , 'test' : test_set})\n",
    "\n",
    "#dataflow = dict()\n",
    "\n",
    "#for split in data_flow:\n",
    "#    sampler = torch.utils.data.RandomSampler(data_flow[split])\n",
    "#    dataflow[split] = torch.utils.data.DataLoader(\n",
    "#        data_flow[split],\n",
    "#        batch_size=50,\n",
    "#        sampler=sampler,\n",
    "#        num_workers=6,\n",
    "#        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 368\n",
      "valid 79\n",
      "test 80\n"
     ]
    }
   ],
   "source": [
    "for i in dataflow:\n",
    "    print(i, len(dataflow[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iisers/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = HybridModel().to(device)\n",
    "model_without_qf = HybridModel_without_qf().to(device)\n",
    "n_epochs = 3\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "0.005 -0.8903939723968506\n"
     ]
    }
   ],
   "source": [
    "accu_list1 = []\n",
    "loss_list1 = []\n",
    "accu_list2 = []\n",
    "loss_list2 = []\n",
    "\n",
    "def train(dataflow, model, device, optimizer):\n",
    "    for i in range(5):\n",
    "    #for feed_dict in dataflow['train']:\n",
    "        #inputs = feed_dict['image'].to(device)\n",
    "        #targets = feed_dict['can_type'].to(device)\n",
    "        inputs = dataflow['train'][i]['image'].to(device)\n",
    "        targets = dataflow['train'][i]['can_type'].to(device)\n",
    "        #print(targets)\n",
    "        #print(targets.shape)\n",
    "        \n",
    "\n",
    "        outputs = model(inputs)\n",
    "        #print(outputs.shape)\n",
    "        #print(outputs)\n",
    "\n",
    "        #print(inputs)\n",
    "        #loss = F.nll_loss(outputs, targets)\n",
    "        loss = F.binary_cross_entropy(outputs[0][0].to(torch.float32), targets[0].to(torch.float32))\n",
    "        #loss = criterion(outputs[0], targets.view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"loss: {loss.item()}\", end='\\r')\n",
    "\n",
    "\n",
    "def valid_test(dataflow, split, model, device, qiskit=False):\n",
    "    target_all = []\n",
    "    output_all = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(2):\n",
    "        #for feed_dict in dataflow[split]:\n",
    "            #inputs = feed_dict['image'].to(device)\n",
    "            #targets = feed_dict['can_type'].to(device)\n",
    "            inputs = dataflow[split][i]['image'].to(device)\n",
    "            targets = dataflow[split][i]['can_type'].to(device)\n",
    "\n",
    "            outputs = model(inputs, use_qiskit=qiskit)\n",
    "\n",
    "            target_all.append(targets.to(torch.float32))\n",
    "            \n",
    "            output_all.append(outputs[0][0].to(torch.float32))\n",
    "            output_all = [torch.tensor(output_all)]\n",
    "            \n",
    "        target_all = torch.cat(target_all, dim=0)\n",
    "        output_all = torch.cat(output_all, dim=0)\n",
    "        \n",
    "    _, indices = output_all.topk(1, dim=0)\n",
    "   \n",
    "    masks = indices.eq(target_all.expand_as(indices))\n",
    "    size = target_all.shape[0]\n",
    "    corrects = masks.sum().item()\n",
    "    accuracy = corrects / size\n",
    "    loss = F.binary_cross_entropy(output_all, target_all).item()\n",
    "\n",
    "    print(f\"{split} set accuracy: {accuracy}\")\n",
    "    print(f\"{split} set loss: {loss}\")\n",
    "\n",
    "    return accuracy, loss\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # train\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    train(dataflow, model, device, optimizer)\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # valid\n",
    "    accu, loss = valid_test(dataflow, 'test', model, device, )\n",
    "    accu_list1.append(accu)\n",
    "    loss_list1.append(loss)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
