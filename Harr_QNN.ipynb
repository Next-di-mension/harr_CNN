{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import torchquantum as tq\n",
    "import random\n",
    "\n",
    "from torchquantum.datasets import MNIST\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params=[0.5,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchquantum' has no attribute 'qubit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchquantum\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtq\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Define the quantum circuit\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m circ \u001b[39m=\u001b[39m tq\u001b[39m.\u001b[39;49mqubit(\u001b[39m2\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Apply the CU2 gate to the qubits\u001b[39;00m\n\u001b[1;32m      8\u001b[0m theta \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m0.5\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torchquantum' has no attribute 'qubit'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchquantum as tq\n",
    "\n",
    "# Define the quantum circuit\n",
    "circ = tq.(2)\n",
    "\n",
    "# Apply the CU2 gate to the qubits\n",
    "theta = torch.tensor(0.5)\n",
    "phi = torch.tensor(0.25)\n",
    "circ.apply(tq.gate.CU2Gate(theta, phi), (0, 1))\n",
    "\n",
    "# Run the circuit on a quantum device\n",
    "device = tq.QVMDevice()\n",
    "result = device.run(circ)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8776, 1.0000, 1.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq2 = 1/np.sqrt(2)\n",
    "ch = [[1,0,0,0],[0,sq2,0,sq2],[0,0,1,0],[0,sq2,0,-sq2]]\n",
    "q_dev = tq.QuantumDevice(n_wires=3)\n",
    "q_dev.apply(tq.RX(has_params=True,  init_params= 0.5,wires=[0]))\n",
    "q_dev.apply(tq.QubitUnitary(\n",
    "   has_params=True,init_params=([[1,0,0,0],[0,sq2,0,sq2],[0,0,1,0],[0,sq2,0,-sq2]]),wires=[0]))\n",
    "k =[]\n",
    "for i in range(3):\n",
    "   k.append(tq.expval(q_dev,wires=i, observables= tq.PauliZ(wires=i)))\n",
    "#b = tq.MeasureAll(tq.PauliZ)\n",
    "#print(b(q_dev))\n",
    "#print(a1)\n",
    "k = torch.tensor([k])\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10, 3]' is invalid for input of size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m bsz \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> 2\u001b[0m k\u001b[39m.\u001b[39;49mview(bsz, \u001b[39m3\u001b[39;49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[10, 3]' is invalid for input of size 3"
     ]
    }
   ],
   "source": [
    "bsz = 10\n",
    "k.view(bsz, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b(q_dev).type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tensor([[0.8776]]), tensor([[1.]]), tensor([[1.]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8776, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b(q_dev)[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(b(q_dev).shape)\n",
    "print(k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sq2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m q_dev\u001b[39m.\u001b[39mapply(tq\u001b[39m.\u001b[39mPauliX(wires \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m))\n\u001b[1;32m      7\u001b[0m q_dev\u001b[39m.\u001b[39mapply(tq\u001b[39m.\u001b[39mPauliX(wires \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m controlled_H(q_dev,\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m \u001b[39m#q_dev.apply(tq.QubitUnitary(\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m#   has_params=True,init_params=(ch),wires=[1,0])) # wires = [target, control]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(q_dev)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mcontrolled_H\u001b[0;34m(qdev, target, control)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcontrolled_H\u001b[39m(qdev, target,control):\n\u001b[1;32m      2\u001b[0m       qdev\u001b[39m.\u001b[39mapply(tq\u001b[39m.\u001b[39mQubitUnitary(\n\u001b[0;32m----> 3\u001b[0m       has_params\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,init_params\u001b[39m=\u001b[39m([[\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,sq2,\u001b[39m0\u001b[39m,sq2],[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m,sq2,\u001b[39m0\u001b[39m,\u001b[39m-\u001b[39msq2]]),wires\u001b[39m=\u001b[39m[target,control]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sq2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def controlled_H(qdev, target,control):\n",
    "      qdev.apply(tq.QubitUnitary(\n",
    "      has_params=True,init_params=([[1,0,0,0],[0,sq2,0,sq2],[0,0,1,0],[0,sq2,0,-sq2]]),wires=[target,control]))\n",
    "     \n",
    "q_dev = tq.QuantumDevice(n_wires=2)\n",
    "q_dev.apply(tq.PauliX(wires = 0))\n",
    "q_dev.apply(tq.PauliX(wires = 1))\n",
    "controlled_H(q_dev,1,0)\n",
    "#q_dev.apply(tq.QubitUnitary(\n",
    "#   has_params=True,init_params=(ch),wires=[1,0])) # wires = [target, control]\n",
    "print(q_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuanvolutionFilter(tq.QuantumModule):\n",
    "  # the __init__ method initializes the quantum device, the general encoder,\n",
    "  # a random quantum layer, and a measurement operator.\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n_wires = 4 + 2 \n",
    "        self.q_device = tq.QuantumDevice(n_wires=self.n_wires)\n",
    "        # encoding the input data\n",
    "        self.encoder = tq.GeneralEncoder(\n",
    "        [   {'input_idx': [0], 'func': 'ry', 'wires': [0]},\n",
    "            {'input_idx': [1], 'func': 'ry', 'wires': [1]},\n",
    "            {'input_idx': [2], 'func': 'ry', 'wires': [2]},\n",
    "            {'input_idx': [3], 'func': 'ry', 'wires': [3]},])\n",
    "        \n",
    "\n",
    "\n",
    "        # random circuit layer \n",
    "        self.q_layer = tq.RandomLayer(n_ops=8, wires=list(range(self.n_wires)))\n",
    "        self.measure = tq.MeasureAll(tq.PauliZ)\n",
    "        #self.expval = tq.expval()\n",
    "    \n",
    "# x has the dimension of (batch_size, 28, 28) representing a batch of greyscale images\n",
    "#The method first reshapes the input data into a 2D array of shape \n",
    "#(batch_size, 784) by concatenating adjacent 2x2 blocks of pixels.\n",
    "# data is the new reshaped tensor \n",
    "    def forward(self, x, use_qiskit=False):\n",
    "        bsz = x.shape[0] # batch size\n",
    "        size = 28 # height and width of an image\n",
    "        x = x.view(bsz, size, size) # view all data \n",
    "\n",
    "        data_list = []\n",
    "\n",
    "        for c in range(0, size, 2):\n",
    "            for r in range(0, size, 2):\n",
    "                data = torch.transpose(torch.cat((x[:, c, r], x[:, c, r+1], x[:, c+1, r], x[:, c+1, r+1])).view(4, bsz), 0, 1)\n",
    "                if use_qiskit:\n",
    "                    data = self.qiskit_processor.process_parameterized(\n",
    "                        self.q_device, self.encoder, self.q_layer, self.measure, data)\n",
    "                else:\n",
    "                    self.encoder(self.q_device, data)\n",
    "                    \n",
    "                    #haar wavelet\n",
    "                    # level 1 \n",
    "                    self.q_device.h(wires = 3) \n",
    "                    self.q_device.swap([3,2])\n",
    "                    self.q_device.swap([2,1])\n",
    "                    self.q_device.swap([1,0])\n",
    "\n",
    "                    # level 2 \n",
    "                    controlled_H(self.q_device, target=2, control= 3)\n",
    "                    self.q_device.cswap([3,2,1])\n",
    "                    self.q_device.cswap([3,1,0])\n",
    "\n",
    "                    # level 3\n",
    "                    self.q_device.ccx([2,3,4])\n",
    "                    controlled_H(self.q_device, target=1, control= 4)\n",
    "                    self.q_device.ccx([2,3,4])\n",
    "                    #perm\n",
    "                    self.q_device.ccx([2,3,4])\n",
    "                    self.q_device.cswap([4,1,0])\n",
    "                    self.q_device.ccx([2,3,4])\n",
    "\n",
    "                    #level 4\n",
    "                    self.q_device.ccx([2,3,4])\n",
    "                    self.q_device.ccx([1,4,5])\n",
    "                    controlled_H(self.q_device, target=0, control= 5)\n",
    "                    self.q_device.ccx([1,4,5])\n",
    "                    self.q_device.ccx([2,3,4])\n",
    "\n",
    "\n",
    "\n",
    "                    self.q_layer(self.q_device)\n",
    "                    data = self.measure(self.q_device)\n",
    "                    #data = []\n",
    "                    #for i in range(4):\n",
    "                    #    data.append(tq.expval(self.q_device,wires=i, observables= tq.PauliZ(wires=i)))\n",
    "\n",
    "                    #data = torch.tensor([data])\n",
    "\n",
    "                    \n",
    "                data_list.append(data[0][:4].view(bsz, 4)) # only keep the first 4 qubits\n",
    "        \n",
    "        result = torch.cat(data_list, dim=1).float()\n",
    "        \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuanvolutionFilter(\n",
       "  (q_device):  class: QuantumDevice \n",
       "   device name: default \n",
       "   number of qubits: 6 \n",
       "   batch size: 1 \n",
       "   current computing device: cpu \n",
       "   current states: [[1.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
       "    0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
       "    0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
       "    0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
       "    0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
       "    0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n",
       "    0.+0.j 0.+0.j 0.+0.j 0.+0.j]]\n",
       "  (encoder): GeneralEncoder()\n",
       "  (q_layer): RandomLayer(\n",
       "    (op_list): QuantumModuleList(\n",
       "      (0):  class: RY \n",
       "       parameters: Parameter containing:\n",
       "      tensor([[1.1869]], requires_grad=True) \n",
       "       wires: [4] \n",
       "       inverse: False\n",
       "      (1):  class: RY \n",
       "       parameters: Parameter containing:\n",
       "      tensor([[-0.0637]], requires_grad=True) \n",
       "       wires: [0] \n",
       "       inverse: False\n",
       "      (2):  class: RX \n",
       "       parameters: Parameter containing:\n",
       "      tensor([[-0.2469]], requires_grad=True) \n",
       "       wires: [5] \n",
       "       inverse: False\n",
       "      (3):  class: RX \n",
       "       parameters: Parameter containing:\n",
       "      tensor([[-0.0418]], requires_grad=True) \n",
       "       wires: [0] \n",
       "       inverse: False\n",
       "      (4):  class: RZ \n",
       "       parameters: Parameter containing:\n",
       "      tensor([[2.1124]], requires_grad=True) \n",
       "       wires: [0] \n",
       "       inverse: False\n",
       "      (5):  class: RY \n",
       "       parameters: Parameter containing:\n",
       "      tensor([[-2.2131]], requires_grad=True) \n",
       "       wires: [0] \n",
       "       inverse: False\n",
       "      (6):  class: RY \n",
       "       parameters: Parameter containing:\n",
       "      tensor([[-2.8212]], requires_grad=True) \n",
       "       wires: [4] \n",
       "       inverse: False\n",
       "      (7):  class: CNOT \n",
       "       parameters: None \n",
       "       wires: [3, 5] \n",
       "       inverse: False\n",
       "    )\n",
       "  )\n",
       "  (measure): MeasureAll()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QuanvolutionFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0min_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mout_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
      "\n",
      "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      "\n",
      "On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
      "\n",
      "Args:\n",
      "    in_features: size of each input sample\n",
      "    out_features: size of each output sample\n",
      "    bias: If set to ``False``, the layer will not learn an additive bias.\n",
      "        Default: ``True``\n",
      "\n",
      "Shape:\n",
      "    - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
      "      dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
      "    - Output: :math:`(*, H_{out})` where all but the last dimension\n",
      "      are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
      "\n",
      "Attributes:\n",
      "    weight: the learnable weights of the module of shape\n",
      "        :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      "        initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      "        :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "    bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      "            If :attr:`bias` is ``True``, the values are initialized from\n",
      "            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      "\n",
      "Examples::\n",
      "\n",
      "    >>> m = nn.Linear(20, 30)\n",
      "    >>> input = torch.randn(128, 20)\n",
      "    >>> output = m(input)\n",
      "    >>> print(output.size())\n",
      "    torch.Size([128, 30])\n",
      "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     NonDynamicallyQuantizableLinear, LazyLinear, Linear, LinearBn1d, Linear\n"
     ]
    }
   ],
   "source": [
    "torch.nn.Linear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HybridModel(torch.nn.Module): # nn.Module is the base class for all neural network modules\n",
    "    def __init__(self): # inherit from nn.Module\n",
    "        super().__init__() # super calls the initialization method of the parent class nn.module\n",
    "        self.qf = QuanvolutionFilter()\n",
    "        self.linear = torch.nn.Linear(4*14*14, 10) # self.linear is a linear layer with 10 output units, outputting the logits for each class\n",
    "    # here the input size is 4*14*14 because the input is reshaped into 4*14*14 after the quanvolution filter\n",
    "    # 10 is the number of classes. classes are u\n",
    "    def forward(self, x, use_qiskit=False):\n",
    "        with torch.no_grad():\n",
    "          x = self.qf(x, use_qiskit)\n",
    "        x = self.linear(x)\n",
    "        return F.log_softmax(x, -1) # log_softmax is the activation function for the output layer\n",
    "\n",
    "class HybridModel_without_qf(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(28*28, 10)\n",
    "    \n",
    "    def forward(self, x, use_qiskit=False):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.linear(x)\n",
    "        return F.log_softmax(x, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2454, -2.3707, -2.3760, -2.2943, -2.3218, -2.3706, -1.9413, -2.5021,\n",
      "         -2.0558, -2.7807]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = HybridModel()\n",
    "x = torch.randn(1,784)  # 64 is the batch size\n",
    "print(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtrain_valid_split_ratio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcenter_crop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresize_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbinarize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbinarize_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1307\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdigits_of_interest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_test_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_valid_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfashion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_train_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "dict() -> new empty dictionary\n",
      "dict(mapping) -> new dictionary initialized from a mapping object's\n",
      "    (key, value) pairs\n",
      "dict(iterable) -> new dictionary initialized as if via:\n",
      "    d = {}\n",
      "    for k, v in iterable:\n",
      "        d[k] = v\n",
      "dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      "    in the keyword argument list.  For example:  dict(one=1, two=2)\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/torchquantum/datasets/mnist.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "MNIST?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glioma = np.load('/home/iisers/Documents/MRI_dataset/glioma_tumor/batch_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.4 MB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy<1.9.2,>=1.8; python_version <= \"3.9\" in /home/iisers/.local/lib/python3.8/site-packages (from scikit-image) (1.8.1)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.8 in /home/iisers/.local/lib/python3.8/site-packages (from scikit-image) (2.8.8)\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2023.3.15-py3-none-any.whl (218 kB)\n",
      "\u001b[K     |████████████████████████████████| 218 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/iisers/.local/lib/python3.8/site-packages (from scikit-image) (22.0)\n",
      "Collecting lazy_loader>=0.1\n",
      "  Downloading lazy_loader-0.1-py3-none-any.whl (8.6 kB)\n",
      "Collecting imageio>=2.4.1\n",
      "  Downloading imageio-2.26.0-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.1 in /home/iisers/.local/lib/python3.8/site-packages (from scikit-image) (1.23.5)\n",
      "Collecting pillow>=9.0.1\n",
      "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: PyWavelets, tifffile, lazy-loader, pillow, imageio, scikit-image\n",
      "Successfully installed PyWavelets-1.4.1 imageio-2.26.0 lazy-loader-0.1 pillow-9.4.0 scikit-image-0.20.0 tifffile-2023.3.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Oral_Can_Data(Dataset):\n",
    "    def __init__(self, csv_file, root_dir,transform = None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations) # returns the number of samples in the dataset\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return (image, y_label) # returns the image and the label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/iisers/Documents/oral cancer project/labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[39m=\u001b[39m Oral_Can_Data(csv_file\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/home/iisers/Documents/oral cancer project/labels.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,root_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/home/iisers/Documents/oral cancer project/Combined_data\u001b[39;49m\u001b[39m'\u001b[39;49m, transform \u001b[39m=\u001b[39;49m transforms\u001b[39m.\u001b[39;49mToTensor())\n",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m, in \u001b[0;36mOral_Can_Data.__init__\u001b[0;34m(self, csv_file, root_dir, transform)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, csv_file, root_dir,transform \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mannotations \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(csv_file)\n\u001b[1;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir \u001b[39m=\u001b[39m root_dir\n\u001b[1;32m      5\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39m=\u001b[39m transform\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/iisers/Documents/oral cancer project/labels.csv'"
     ]
    }
   ],
   "source": [
    "dataset = Oral_Can_Data(csv_file='/home/iisers/Documents/oral cancer project/labels.csv',root_dir='/home/iisers/Documents/oral cancer project/Combined_data', transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:12<00:00, 818016.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2434398.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 1807160.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2128075.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2023-03-16 13:10:30.311] Only use the front 50 images as TRAIN set.\n",
      "[2023-03-16 13:10:30.406] Only use the front 30 images as TEST set.\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "dataset = MNIST(\n",
    "    root='./mnist_data',\n",
    "    train_valid_split_ratio=[0.9, 0.1],\n",
    "    n_test_samples=30,\n",
    "    n_train_samples=50,\n",
    ")\n",
    "dataflow = dict()\n",
    "\n",
    "for split in dataset:\n",
    "    sampler = torch.utils.data.RandomSampler(dataset[split])\n",
    "    dataflow[split] = torch.utils.data.DataLoader(\n",
    "        dataset[split],\n",
    "        batch_size=1,\n",
    "        sampler=sampler,\n",
    "        num_workers=6,\n",
    "        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iisers/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = HybridModel().to(device) # model is a HybridModel\n",
    "model_without_qf = HybridModel_without_qf().to(device)\n",
    "n_epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-3, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "0.005 3.8555865287780762\n",
      "test set accuracy: 0.26666666666666666\n",
      "test set loss: 1.929352879524231\n",
      "Epoch 2:\n",
      "0.004522542485937368540226\n",
      "test set accuracy: 0.5333333333333333\n",
      "test set loss: 1.4241527318954468\n",
      "Epoch 3:\n",
      "0.003272542485937368317686\n",
      "test set accuracy: 0.4666666666666667\n",
      "test set loss: 1.3936468362808228\n",
      "Epoch 4:\n",
      "0.0017274575140626314981266\n",
      "test set accuracy: 0.5666666666666667\n",
      "test set loss: 1.446394681930542\n",
      "Epoch 5:\n",
      "0.0004774575140626316650633\n",
      "test set accuracy: 0.7333333333333333\n",
      "test set loss: 1.223548173904419\n"
     ]
    }
   ],
   "source": [
    "accu_list1 = []\n",
    "loss_list1 = []\n",
    "accu_list2 = []\n",
    "loss_list2 = []\n",
    "\n",
    "def train(dataflow, model, device, optimizer):\n",
    "    for feed_dict in dataflow['train']:\n",
    "        inputs = feed_dict['image'].to(device)\n",
    "        targets = feed_dict['digit'].to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = F.nll_loss(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"loss: {loss.item()}\", end='\\r')\n",
    "\n",
    "\n",
    "def valid_test(dataflow, split, model, device, qiskit=False):\n",
    "    target_all = []\n",
    "    output_all = []\n",
    "    with torch.no_grad():\n",
    "        for feed_dict in dataflow[split]:\n",
    "            inputs = feed_dict['image'].to(device)\n",
    "            targets = feed_dict['digit'].to(device)\n",
    "\n",
    "            outputs = model(inputs, use_qiskit=qiskit)\n",
    "\n",
    "            target_all.append(targets)\n",
    "            output_all.append(outputs)\n",
    "        target_all = torch.cat(target_all, dim=0)\n",
    "        output_all = torch.cat(output_all, dim=0)\n",
    "\n",
    "    _, indices = output_all.topk(1, dim=1)\n",
    "    masks = indices.eq(target_all.view(-1, 1).expand_as(indices))\n",
    "    size = target_all.shape[0]\n",
    "    corrects = masks.sum().item()\n",
    "    accuracy = corrects / size\n",
    "    loss = F.nll_loss(output_all, target_all).item()\n",
    "\n",
    "    print(f\"{split} set accuracy: {accuracy}\")\n",
    "    print(f\"{split} set loss: {loss}\")\n",
    "\n",
    "    return accuracy, loss\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    # train\n",
    "    print(f\"Epoch {epoch}:\")\n",
    "    train(dataflow, model, device, optimizer)\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    # valid\n",
    "    accu, loss = valid_test(dataflow, 'test', model, device, )\n",
    "    accu_list1.append(accu)\n",
    "    loss_list1.append(loss)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
